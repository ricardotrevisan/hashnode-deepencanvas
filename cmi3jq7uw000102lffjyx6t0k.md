---
title: "The Emergence of Structured Intelligence"
datePublished: Mon Nov 17 2025 19:37:06 GMT+0000 (Coordinated Universal Time)
cuid: cmi3jq7uw000102lffjyx6t0k
slug: the-emergence-of-structured-intelligence
cover: https://raw.githubusercontent.com/ricardotrevisan/ricardotrevisan.github.io/master/images/image_1_20251016.png
tags: deeplearning, cognition, reasoning, artificialintelligence, airesearch, symbolicai, tensorlogic, neurosymbolicai

---

Artificial intelligence has split into two worlds: symbolic logic, which reasons about facts and rules; and neural networks, which learn patterns without being able to explain them.

On one side, deductive intelligence — precise, coherent, but rigid.
On the other, associative intelligence — flexible, adaptive, but opaque.

Common to both is their failure to achieve understanding, merely repeating rules or probabilistic deductions.

Now a refined domain appears: a form of structured and adaptive intelligence — formalized in proposals like Tensor Logic, by Pedro Domingos. A paradigm that unites logical reasoning and continual learning within a single mathematical formalism, using the same data structures that let us discuss AI daily.

In his proposal, Domingos shows it's possible to represent facts and logical rules as tensors, uniting symbolic reasoning and numerical learning. It's like teaching a network to reason, not just predict.

In this new approach, inference and learning cease to be separate fields. Facts and rules are represented as tensors; deduction and optimization become differentiable operations of a single equation.

Logic ceases to be static and gains plasticity.
The network ceases to be blind and gains structure.
The result is a model that can think and learn simultaneously.

He adds to the associative intelligence of current neural networks logical relations, constraints, and ways to infer new truths — deductive intelligence. This integration opens the path for neuro-symbolic architectures, where perception, reasoning, and metacognition coexist in balance.

But there are risks, of course. High-level abstractions can cause us to lose desirable properties of symbolic logic — such as exactness, completeness, and clear interpretation — when relaxing to the continuous: by representing logic as numeric vectors, we also transform discrete propositions (true or false) into continuous and gradated representations, expressing degrees of truth.

This relaxation, though risky, brings AI closer to a more organic functioning — the human brain already does this naturally, coordinating autonomous modules of perception, language, memory, and control under a single dynamic system. In studies like Domingos', we begin to reproduce this principle.

The boundary is no longer between symbols and neurons — but between correlation and consciousness, between processing and understanding.
Thinking about thinking has never been a light task — and perhaps that is where intelligence truly begins. My head feels heavy right now.

Today we pay tribute to Aristotle — the father of Logic — and Gauss — the father of Statistics.

**Sources:**
• Pedro Domingos — *Tensor Logic* (arXiv, 2025) : https://arxiv.org/html/2510.12269v2
• Yoshua Bengio — *System 2 Deep Learning* : https://www.youtube.com/watch?v=FtUbMG3rlFs
• IBM — *Neuro-Symbolic AI Initiative* : https://cacm.acm.org/news/neurosymbolic-ai/

#TensorLogic #NeuroSymbolicAI #ArtificialIntelligence #SymbolicAI #DeepLearning #Reasoning #Cognition #AIResearch