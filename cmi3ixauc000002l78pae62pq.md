---
title: "Generative AI puts the pillars of open source to the test"
datePublished: Mon Nov 17 2025 19:14:37 GMT+0000 (Coordinated Universal Time)
cuid: cmi3ixauc000002l78pae62pq
slug: generative-ai-puts-the-pillars-of-open-source-to-the-test
cover: https://raw.githubusercontent.com/ricardotrevisan/ricardotrevisan.github.io/master/images/image_20251024.png
tags: ai, opensourcesoftware

---

Or are we just debating what AI can "see" and how far it can be inspired?

Seeing isn‚Äôt using. Learning isn‚Äôt copying. In fact, it‚Äôs the basis of human learning: we observe patterns, abstract logic, and reinterpret the world.

But the rights involved in licenses don‚Äôt cover this context. They still don‚Äôt distinguish observation from reproduction. Once again, we watch an old system trying to adapt to judge a phenomenon it doesn‚Äôt understand.

When the final product of a model is a weight matrix, who is the author of any potential byproduct? Law protects fixed expressions, not learned patterns.

AI training is statistical learning‚Äînot literal copying. A model‚Äôs weights don‚Äôt store lines of code, but relationships between tokens. They are abstractions, not reproductions.

What AI does is what every programmer does: observe, abstract, and reinterpret. Training a model is the digital equivalent of reading thousands of libraries and, from them, writing something new. There is no owner of the for loop, of the if conditional, or of the concept of a recursive function. The problem is that current laws lack the language to describe this emergent creativity.

But is there a future for open source? Yes‚Äîand it‚Äôs not about opening code anymore, but about opening cognition.

In this context, AI could be the opposite of what we fear: the new engine of collective knowledge.

If a model doesn‚Äôt copy, but synthesizes relationships, then it is a new kind of creator ‚Äî an observer of the information world. It abstracts patterns and returns them as syntheses. AI doesn‚Äôt destroy open knowledge; it redistributes it on a planetary scale.

The expansion of open source may come precisely from this generative synthesis. Open models, trained on public data, can deliver learning in the form of code, text, or insights ‚Äî multiplying the reach of what previously depended on restricted communities.

What used to be ‚Äúsharing code‚Äù becomes ‚Äúsharing learning.‚Äù This transition redefines the meaning of openness.

OSS (Open Source Software) opened deterministic instructions. An algorithm was like a cake recipe: clear inputs, precise steps, reproducibility.

Now, models share relationships between observations ‚Äî the ability to recombine. Therefore, what we share is no longer a manual, but a way of perceiving and synthesizing the world.

#AI #OpenSourceSoftware

üìö **Sources:**

‚Ä¢ Why open source may not survive the rise of generative AI: https://www.zdnet.com/article/why-open-source-may-not-survive-the-rise-of-generative-ai/

‚Ä¢ Reddit sues Perplexity for allegedly ripping its content to feed AI: https://www.theverge.com/news/804660/reddit-suing-perplexity-data-scrapers-ai-lawsuit