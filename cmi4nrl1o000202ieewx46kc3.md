---
title: "Surrogate Models and the Bridge Professional"
datePublished: Tue Nov 18 2025 14:17:55 GMT+0000 (Coordinated Universal Time)
cuid: cmi4nrl1o000202ieewx46kc3
slug: surrogate-models-and-the-bridge-professional
cover: https://raw.githubusercontent.com/ricardotrevisan/ricardotrevisan.github.io/master/images/img_1_20251118.png
tags: ai, scientificcomputing, energyefficiency, hybridai, accelerators, surrogatemodels, bridgeprofessional, mixedprecision, physicsinformedml, surrogatemodelsinindustry

---

It's in the realm of science that the traditional corporate world typically seeks inspiration to expand opportunities, create competitive advantage, and anticipate risks. In recent years, scientific computation has undergone a historic turn—not a discrete evolution, but a paradigm shift. The explosive blend of accelerators, mixed precision, AI, and simulation is redefining how we investigate complex phenomena: climate, energy, biology, materials, fluid dynamics, and physical risk models.

The central point is simple: the same move that revolutionized science is about to sweep the corporate world with even greater intensity.

## The logic starts with mixed precision

For decades, scientific simulation meant FP64, double precision, giant matrices, and hours of compute. It was a costly domain, restricted to supercomputers, and the implicit rule was: more precision = more truth. But that equation has changed.

When AI took the spotlight, the market realized something obvious in hindsight but invisible at the time: not every calculation requires FP64 — quite the opposite. Lower precisions like FP32, FP16, BF16, and FP8 solve most problems, especially when combined with hybrid techniques and specialized operators. It’s pure empirical knowledge: the right precision varies with the stage, the nature of the phenomenon, and the physical sensitivity of the model.

GPUs evolved exactly for this mixed-precision world. They deliver 10x to 100x more energy efficiency than CPUs, leverage massive parallelism, and naturally become the ideal habitat for simulation + AI. Adoption was inevitable: science moved to accelerators because they enable using the right precision, at the right time, for the right problem. And the currency now isn’t FLOP — it’s FLOP per watt.

## The real leap came from the fusion of physics and artificial intelligence

The true revolution wasn’t the hardware.  
It was the shift in understanding: **physical simulation and AI don’t compete — they complement each other.**

Physics stays where it’s indispensable.  
AI takes over where physics is costly, slow, or impractical.

From this meeting arose the field that redesigns research infrastructure:  
**Mixed Precision Scientific Computing — physics + AI + accelerators + mixed precision in a single coherent pipeline.**

Hybrid climate forecasting models, turbines with neural turbulence, operators like Fourier Neural Operators or DeepONets, and techniques like PINNs symbolize this new universe. All share the same essence: combine physical exactness with computational efficiency.

## That’s where surrogate models emerge

Solving climate PDEs, radiation, nuclear fusion, advanced materials, or high-resolution fluids is prohibitively expensive — and will continue to be. The surrogate model is born exactly from the physical limits of traditional computation. It is a neural model that replaces, approximates, or accelerates parts of the original physics with:

- speeds tens to thousands of times faster  
- energy consumption irrisorially low  
- precision sufficient for decision making  
- generalization capability superior to local deterministic methods  

Surrogate models aren’t tricks.  
They’re the only viable path to scale problems that were literally impossible before. And the most interesting part: this logic is already descending into the corporate world.

## The convergence with the corporate world is inevitable

Companies today face the same dilemma laboratories faced ten years ago:  
ever larger models, decisions that must be made in real time, data explosions, CPU bottlenecks, and energy costs that can’t be ignored. Moreover, regulatory pressure is rising — and more precise predictions are no longer a luxury but a survival condition.

It’s no surprise corporations are migrating to the same ecosystem:

- accelerators (GPU, TPU, quantized inference)  
- aggressive mixed precision (INT8/FP8)  
- hybrid pipelines: deterministic rules + AI  
- corporate surrogates (risk, demand, logistics approximators)  
- watt-per-efficiency as an operational metric  

Fintechs already use quantized models for fraud and real-time scoring.  
Retail blends neural forecasts with traditional heuristics.  
Industry uses AI as a proxy for predictive maintenance simulation.  
Energy mixes load-physics models with neural operators.  
Insurance begins pricing climate risk with accelerated simulations.

**This isn’t the future. It’s happening now, and fast.**

## Enter the “bridge” professional

As complexity rises, the corporate market begins to demand a new kind of talent: someone able to cross disciplinary borders, blend physical intuition with AI, understand systems, energy, architecture, efficiency metrics, and translate all of this into business impact.

Traditional barriers — data versus systems, product versus engineering, physicist versus dev — have collapsed.  
The “half-discipline” professional is becoming obsolete.  
The game now rewards those who can operate at the intersection: **the bridge.**

## And with it come the structural soft skills: patterns, partnerships, and governance

Nothing we discuss here happens in isolation.  
In science, no one builds a supercomputer like JUPITER, Frontier, or Aurora alone. It’s co-design, partnerships, consortia, and end-to-end governance.

The corporate world is starting to mirror the same logic:  
agreements with hyperscalers, AI energy policies, compute consumption audits, internal frameworks for algorithmic risk, compliance certifications, and sectoral consortia for shared infrastructure.

Scientific governance quietly becomes corporate governance of AI.

## The end point of this convergence

Science arrived first.  
The corporate world is following — driven by the same structural factors:

- the need for energy efficiency  
- explosive model growth  
- demand for speed  
- pressure for precision  
- the operating cost of AI  
- the inevitable evolution of infrastructure  
- the growing complexity of systems  

Sectors like banking, retail, industry, health, telecom, logistics, energy, and insurance have already begun this transition. Some explicitly; others quietly, adopting pieces of this new paradigm without announcement.

The scientific frontier and the corporate frontier are merging.  
Both demand watt-efficient performance, hybrid intelligence, deep software-hardware integration, mathematical rigor, product vision, governance, and a rare capacity to navigate growing complexity.

The competitive edge of the coming years will come from people who understand the entire system.  
Energy. Hardware. Mathematics. AI. Operations. Business. Risk.

Again, it’s science being applied to business.  
Anticipating this convergence — with systemic view, technical mastery, and cooperative capacity — is essential for the next decade of innovations and products that broaden and democratize quality of life for all.

Sources:
- NVIDIA - The Great Flip: https://blogs.nvidia.com/blog/accelerated-scientific-systems/
- Demonstration of a PINN for Heat Dissipation (1D): https://github.com/ricardotrevisan/poisson-mlp.git

# Hashtags
#SurrogateModels #BridgeProfessional #MixedPrecision #ScientificComputing #AI #Accelerators #HybridAI #PhysicsInformedML #SurrogateModelsInIndustry #EnergyEfficiency