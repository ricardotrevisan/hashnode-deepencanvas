---
title: "The Illusory Confidence of AI"
datePublished: Mon Nov 17 2025 20:05:44 GMT+0000 (Coordinated Universal Time)
cuid: cmi3kr0zk000402jm0jsxeglt
slug: the-illusory-confidence-of-ai
cover: https://raw.githubusercontent.com/ricardotrevisan/ricardotrevisan.github.io/master/images/image_1_20251003.png
tags: ai, machinelearning, artificialintelligence, languagemodels, techethics, aiethics

---

Imagine asking for someone's birthday.
If the model answers ‚ÄúSeptember 10,‚Äù it has a 1/365 chance of getting it right.
If it answers ‚ÄúI don‚Äôt know,‚Äù the score is zero.

In large-scale testing, the model that dares to answer seems better than the cautious one ‚Äî even though it's wrong most of the time.

This phenomenon, called ‚Äúhallucination,‚Äù comes from the training method itself and the incentives. There are already attempts to mitigate it ‚Äî human feedback, uncertainty calibration, internal checks ‚Äî but the problem persists.

We tolerate human flaws, such as bias, overconfidence, or memory lapses. But we expect AI to be infallible. And when they err with absolute certainty, without hesitating in tone, they convey an illusory authority.

One researcher spent 21 days conversing with ChatGPT, convinced they had discovered a revolutionary new mathematics ‚Äî all fueled by a mutual reinforcement loop between their ideas and the model's responses.

The solution isn't purely technological. It's human too.
Confirm information with other people and real facts. Observe concrete applications before validating theories. Notice when old details are recalled imprecisely. Doubt dialogues that are too coherent to be true.

Sometimes the simplest fix helps: restart the conversation.
A reset breaks the snowball of confirmations and opens space for new perspectives.

Ultimately, AI reminds us of something essential: discernment is still our job.

üìö **Sources:**
- OpenAI: https://openai.com/pt-BR/index/why-language-models-hallucinate/
- TechCrunch: https://techcrunch.com/2025/10/02/ex-openai-researcher-dissects-one-of-chatgpts-delusional-spirals/

#AI #ArtificialIntelligence #AIethics #LanguageModels #MachineLearning #TechEthics